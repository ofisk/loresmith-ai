// Sync Queue Service for managing file indexing operations

import { FileDAO } from "@/dao/file-dao";
import { LibraryRAGService } from "@/services/rag/rag-service";
import type { FileMetadata } from "@/types/upload";
import { notifyMetadataAutoGenerated } from "@/lib/notifications";

export class SyncQueueService {
  /**
   * Process a file upload - index file directly with LibraryRAGService
   */
  static async processFileUpload(
    env: any,
    username: string,
    fileKey: string,
    fileName: string,
    _jwt?: string
  ): Promise<{ queued: boolean; jobId?: string; message: string }> {
    const startTime = Date.now();
    console.log(`[DEBUG] [SyncQueue] ===== PROCESSING FILE UPLOAD =====`);
    console.log(`[DEBUG] [SyncQueue] File: ${fileName}`);
    console.log(`[DEBUG] [SyncQueue] File Key: ${fileKey}`);
    console.log(`[DEBUG] [SyncQueue] User: ${username}`);
    console.log(`[DEBUG] [SyncQueue] Timestamp: ${new Date().toISOString()}`);

    const fileDAO = new FileDAO(env.DB);

    // Process file directly with LibraryRAGService
    try {
      console.log(
        `[DEBUG] [SyncQueue] Processing file with LibraryRAGService...`
      );

      // Get file from R2
      const file = await env.R2.get(fileKey);
      if (!file) {
        throw new Error(`File not found: ${fileKey}`);
      }

      // Get file metadata from database
      const dbMetadata = await fileDAO.getFileForRag(fileKey, username);
      if (!dbMetadata) {
        throw new Error(`File metadata not found in database: ${fileKey}`);
      }

      // Process file with LibraryRAGService
      const ragService = new LibraryRAGService(env);
      const fileMetadata: FileMetadata = {
        id: dbMetadata.file_key, // Use file_key as id since processFile expects id
        fileKey: dbMetadata.file_key,
        userId: dbMetadata.username,
        filename: dbMetadata.file_name,
        fileSize: dbMetadata.file_size || 0,
        contentType:
          dbMetadata.content_type || file.httpMetadata?.contentType || "",
        tags: dbMetadata.tags ? JSON.parse(dbMetadata.tags) : [],
        status: dbMetadata.status || "uploaded",
        createdAt: dbMetadata.created_at || new Date().toISOString(),
        updatedAt: dbMetadata.updated_at || new Date().toISOString(),
      };

      const processResult = await ragService.processFile(fileMetadata);

      // Save generated metadata, respecting user-provided values
      const metadataUpdates: {
        display_name?: string;
        description?: string;
        tags?: string;
      } = {};

      // Only update fields that are empty/null in database (user-provided values take precedence)
      if (processResult.displayName && !dbMetadata.display_name) {
        metadataUpdates.display_name = processResult.displayName;
      }
      if (processResult.description && !dbMetadata.description) {
        metadataUpdates.description = processResult.description;
      }
      if (processResult.tags && processResult.tags.length > 0) {
        const existingTags = dbMetadata.tags ? JSON.parse(dbMetadata.tags) : [];
        if (existingTags.length === 0) {
          metadataUpdates.tags = JSON.stringify(processResult.tags);
        }
      }

      // Save metadata updates if any
      if (Object.keys(metadataUpdates).length > 0) {
        await fileDAO.updateFileMetadata(fileKey, metadataUpdates);

        // Send notification for auto-generated metadata
        try {
          await notifyMetadataAutoGenerated(env, username, fileName, {
            displayName: metadataUpdates.display_name,
            description: metadataUpdates.description,
            tags: metadataUpdates.tags
              ? JSON.parse(metadataUpdates.tags)
              : undefined,
          });
        } catch (notifError) {
          console.error(
            "[SyncQueue] Failed to send metadata generation notification:",
            notifError
          );
        }
      }

      // Update file status to uploaded (indexed)
      await fileDAO.updateFileRecord(fileKey, FileDAO.STATUS.UPLOADED);

      const endTime = Date.now();
      const duration = endTime - startTime;
      console.log(
        `[DEBUG] [SyncQueue] ===== FILE UPLOAD PROCESSING COMPLETED =====`
      );
      console.log(`[DEBUG] [SyncQueue] Duration: ${duration}ms`);
      console.log(`[DEBUG] [SyncQueue] Status: INDEXED`);

      return {
        queued: false,
        message: `File ${fileName} indexed successfully`,
      };
    } catch (error) {
      const endTime = Date.now();
      const duration = endTime - startTime;
      console.error(
        `[DEBUG] [SyncQueue] ===== FILE UPLOAD PROCESSING FAILED =====`
      );
      console.error(`[DEBUG] [SyncQueue] Duration: ${duration}ms`);
      console.error(
        `[DEBUG] [SyncQueue] Failed to process file ${fileName}:`,
        error
      );

      // Mark file as error if processing fails
      await fileDAO.updateFileRecord(fileKey, FileDAO.STATUS.ERROR);

      return {
        queued: false,
        message: `File ${fileName} processing failed: ${error instanceof Error ? error.message : "Unknown error"}`,
      };
    }
  }

  /**
   * Process the sync queue - process all queued files with LibraryRAGService
   */
  static async processSyncQueue(
    env: any,
    username: string,
    _jwt?: string
  ): Promise<{ processed: number; jobId?: string }> {
    const fileDAO = new FileDAO(env.DB);

    // Get all pending queue items for this user
    const queueItems = await fileDAO.getSyncQueue(username);

    if (queueItems.length === 0) {
      console.log(`[SyncQueue] No items in queue for user ${username}`);
      return { processed: 0 };
    }

    console.log(
      `[SyncQueue] Processing ${queueItems.length} queued items for user ${username}`
    );

    let processed = 0;
    const ragService = new LibraryRAGService(env);

    // Process each queued file
    for (const item of queueItems) {
      try {
        // Get file from R2
        const file = await env.R2.get(item.file_key);
        if (!file) {
          console.error(`[SyncQueue] File not found: ${item.file_key}`);
          await fileDAO.removeFromSyncQueue(item.file_key);
          continue;
        }

        // Get file metadata from database
        const dbMetadata = await fileDAO.getFileForRag(item.file_key, username);
        if (!dbMetadata) {
          console.error(
            `[SyncQueue] File metadata not found: ${item.file_key}`
          );
          await fileDAO.removeFromSyncQueue(item.file_key);
          continue;
        }

        // Process file with LibraryRAGService
        const fileMetadata: FileMetadata = {
          id: dbMetadata.file_key,
          fileKey: dbMetadata.file_key,
          userId: dbMetadata.username,
          filename: dbMetadata.file_name,
          fileSize: dbMetadata.file_size || 0,
          contentType:
            dbMetadata.content_type || file.httpMetadata?.contentType || "",
          tags: dbMetadata.tags ? JSON.parse(dbMetadata.tags) : [],
          status: dbMetadata.status || "uploaded",
          createdAt: dbMetadata.created_at || new Date().toISOString(),
          updatedAt: dbMetadata.updated_at || new Date().toISOString(),
        };

        const processResult = await ragService.processFile(fileMetadata);

        // Save generated metadata, respecting user-provided values
        const metadataUpdates: {
          display_name?: string;
          description?: string;
          tags?: string;
        } = {};

        // Only update fields that are empty/null in database (user-provided values take precedence)
        if (processResult.displayName && !dbMetadata.display_name) {
          metadataUpdates.display_name = processResult.displayName;
        }
        if (processResult.description && !dbMetadata.description) {
          metadataUpdates.description = processResult.description;
        }
        if (processResult.tags && processResult.tags.length > 0) {
          const existingTags = dbMetadata.tags
            ? JSON.parse(dbMetadata.tags)
            : [];
          if (existingTags.length === 0) {
            metadataUpdates.tags = JSON.stringify(processResult.tags);
          }
        }

        // Save metadata updates if any
        if (Object.keys(metadataUpdates).length > 0) {
          await fileDAO.updateFileMetadata(item.file_key, metadataUpdates);
        }

        await fileDAO.updateFileRecord(item.file_key, FileDAO.STATUS.UPLOADED);
        await fileDAO.removeFromSyncQueue(item.file_key);

        processed++;
        console.log(`[SyncQueue] Processed queued file ${item.file_name}`);
      } catch (error) {
        console.error(
          `[SyncQueue] Failed to process queued file ${item.file_name}:`,
          error
        );
        // Remove from queue to avoid infinite retries
        await fileDAO.removeFromSyncQueue(item.file_key);
      }
    }

    return { processed };
  }

  /**
   * Check if a user has any queued items
   */
  static async hasQueuedItems(env: any, username: string): Promise<boolean> {
    const fileDAO = new FileDAO(env.DB);
    const queueItems = await fileDAO.getSyncQueue(username);
    return queueItems.length > 0;
  }

  /**
   * Get queue status for a user
   */
  static async getQueueStatus(
    env: any,
    username: string
  ): Promise<{
    queuedCount: number;
    ongoingJobs: boolean;
    queueItems: any[];
  }> {
    const fileDAO = new FileDAO(env.DB);

    const queueItems = await fileDAO.getSyncQueue(username);

    return {
      queuedCount: queueItems.length,
      ongoingJobs: false, // No ongoing jobs since files are processed directly
      queueItems,
    };
  }
}
